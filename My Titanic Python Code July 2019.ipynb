{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Kaggle Competition\n",
    "\n",
    "In June of 2019 I attended the Data Science Dojo bootcamp. For our capstone project we built a model for the Kaggle Titanic data set. Below is the code I used to generate my model.\n",
    "\n",
    "This is a basic model that doesn't do a lot of feature engineering. Partly this was because I wanted to test the theory around the value of the strength of weak learners. This theory states that many weak learners may perform better than a fewer number of strong learners.\n",
    "\n",
    "To that end, I created a pretty limited Random Forest Tree, and I didn't do much feature engineering beyond creating a variable for family size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the parameters for the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code is a modified version of the \n",
    "original code that is part of Data Science Dojo's bootcamp\n",
    "Copyright (C) 2015-2019\n",
    "\n",
    "Objective: Machine Learning of the Titanic dataset with a Random Forest\n",
    "Data Source: bootcamp root/Datasets/titanic.csv\n",
    "Python Version: 3.4+\n",
    "Packages: scikit-learn, pandas, numpy, sklearn-pandas\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import metrics\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in the data\n",
    "\n",
    "os.chdir('/Users/johnspencer/Desktop/Bootcamp')\n",
    "titanic = pd.read_csv('Datasets/titanic.csv')\n",
    "titanic = titanic.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "### CHANGE THIS FOR TEST\n",
    "#titanic['Survived']='NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S, C, Q]\n",
      "Categories (3, object): [S, C, Q]\n"
     ]
    }
   ],
   "source": [
    "## Set values to categorical and clean NaNs as needed\n",
    "titanic['Survived'] = titanic['Survived'].astype('category')\n",
    "titanic['Pclass'] = titanic['Pclass'].astype('category')\n",
    "titanic.loc[pd.isnull(titanic['Embarked']), 'Embarked'] = 'S'\n",
    "titanic['Embarked'] = titanic['Embarked'].astype('category')\n",
    "titanic['Sex'] = titanic['Sex'].astype('category')\n",
    "\n",
    "print(titanic[\"Embarked\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill_missing_fare function from:https://www.kaggle.com/saisivasriram/titanic-feature-understanding-from-plots\n",
    "def fill_missing_fare(df):\n",
    "    median_fare=df[(df['Pclass'] == 3) & (df['Embarked'] == 'S')]['Fare'].median()\n",
    "#'S'\n",
    "       #print(median_fare)\n",
    "    df[\"Fare\"] = df[\"Fare\"].fillna(median_fare)\n",
    "    return df\n",
    "\n",
    "titanic=fill_missing_fare(titanic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Missing Data\n",
    "\n",
    "In the class, missing age values were assigned the median for all ages. This is a *very* rough way to fill in these missing values. Because of time constraints in the course, I wasn't able to dive too deeply into alternative ways to impute these missing values, so I used a slightly less rough method. I assigned passengers with missing age values the mean value for their sex. Again this isn't ideal but in keeping with my need to balance developing a quick model with an interest in exploring weak learners, it can be a good starting point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This calculates the mean/median by sex. Try running this first. If it doesn't result in a solid model \n",
    "titanic=titanic.copy()\n",
    "g_mean = titanic.groupby('Sex').mean()\n",
    "g_median= titanic.groupby('Sex').median()\n",
    "titanic.loc[titanic.Age.isnull() & (titanic.Sex == 'female'),'Age'] = g_mean['Age']['female']\n",
    "titanic.loc[titanic.Age.isnull() & (titanic.Sex == 'male'), 'Age'] = g_mean['Age']['male']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family Size\n",
    "\n",
    "After exploring the data family size appeared to play a role and indeed in doing some reading on how others have tackled the issue it seemed like it could be an important factor. \n",
    "\n",
    "I decided to add that to my model. So I created a categorical variable that indicates family size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['relatives'] = titanic['SibSp'] + titanic['Parch']\n",
    "titanic.loc[titanic['relatives'] > 0, 'not_alone'] = 0\n",
    "titanic.loc[titanic['relatives'] == 0, 'not_alone'] = 1\n",
    "titanic['not_alone'] = titanic['not_alone'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     537\n",
      "2     161\n",
      "3     102\n",
      "4      29\n",
      "6      22\n",
      "5      15\n",
      "7      12\n",
      "11      7\n",
      "8       6\n",
      "Name: FamilySize, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a family size variable including the passenger themselves\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]+1\n",
    "print(titanic[\"FamilySize\"].value_counts())\n",
    "# Discretize family size\n",
    "titanic.loc[titanic[\"FamilySize\"] == 1, \"FsizeD\"] = '1'\n",
    "titanic.loc[(titanic[\"FamilySize\"] > 1)  &  (titanic[\"FamilySize\"] < 5) , \"FsizeD\"] = '2'\n",
    "titanic.loc[titanic[\"FamilySize\"] >4, \"FsizeD\"] = '3'\n",
    "#titanic[\"FsizeD\"] = pd.to_numeric([\"FsizeD\"])\n",
    "titanic[\"FsizeD\"] = titanic[\"FsizeD\"].astype(np.int64)\n",
    "\n",
    "#print(titanic[\"Embarked\"].unique())\n",
    "#print(titanic[\"FsizeD\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More data cleaning by casting certain variables as categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encode all categorical values as integers\n",
    "## Survived: 0 = Dead, 1 = Alive\n",
    "## Embarked: 0 = Cherbourg, 1 = Queenstown, 2 = Southampton, 3 = Unknown\n",
    "## Sex: 0 = female, 1 = male\n",
    "titanic['Survived'].cat.categories = [0,1]\n",
    "titanic['Embarked'].cat.categories = [0,1,2]\n",
    "titanic['Sex'].cat.categories = [0,1]\n",
    "titanic['Pclass'].cat.categories = [0,1,2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop some variables that we don't need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop(['SibSp', 'Parch', 'FamilySize'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map the variables so the model can be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_map = DataFrameMapper([\n",
    "    (['Pclass'], LabelBinarizer()),\n",
    "    (['Sex'], LabelBinarizer()),\n",
    "    ('Age', None),\n",
    "    ('Fare', None),\n",
    "    (['Embarked'], LabelBinarizer()),\n",
    "    ('relatives', None),\n",
    "    ('not_alone', None),\n",
    "    ('FsizeD', None),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "Now we get down to business by building a `Random Forest Classifier` model.\n",
    "\n",
    "I chose to set a high value for `n_estimators` (the number of trees the model generates) in order to test the weak learner theory. I selected __3__ for the `max_depth` value (the maximum depth of the tree) and a low value of **2** for `min_samples_split`.\n",
    "\n",
    "For some reason I could not get the `OOB Accuracy` value to print. That's a subject for future exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/Bootcamp/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Accuracy: True\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split function\n",
    "titanic_cln_var_names = [ \"Pclass\",\"Sex\",\"Age\",\"Fare\", \"Embarked\",\"relatives\",\"not_alone\",\"FsizeD\"]\n",
    "\n",
    "titanic_features = titanic_map.fit_transform(titanic)\n",
    "\n",
    "\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "np.random.seed(27)\n",
    "titanic.is_train = np.random.uniform(0,1,len(titanic)) <= .7\n",
    "titanic_features_train = titanic_features[titanic.is_train]\n",
    "titanic_features_test = titanic_features[titanic.is_train == False]\n",
    "\n",
    "\n",
    "# Train Model\n",
    "titanic_rf_clf = RandomForestClassifier(oob_score=True, n_jobs=3, n_estimators=1000, \n",
    "                                        max_features='sqrt', criterion='gini', max_depth=3, \n",
    "                                        min_samples_split=2, min_samples_leaf=1\n",
    "                                       )\n",
    "titanic_rf_clf = titanic_rf_clf.fit(titanic_features_train, \n",
    "                                    titanic.loc[titanic.is_train,'Survived'])\n",
    "print(\"OOB Accuracy: \" + str(titanic_rf_clf.oob_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model\n",
    "\n",
    "Now that we have a model let's test it. \n",
    "\n",
    "Again because of time limitations in the course I wasn't able to do cross validation with my model. Next run I'll add that and do more feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150  11]\n",
      " [ 43  62]]\n",
      "Accuracy: 0.7969924812030075\n",
      "Precision: 0.8493150684931506\n",
      "Recall: 0.5904761904761905\n",
      "F1-score: 0.696629213483146\n",
      "AUC: 0.8634723454599231\n"
     ]
    }
   ],
   "source": [
    "testdf_cln_var_names = [ \"Pclass\",\"Sex\",\"Age\",\"Fare\", \"Embarked\",\"relatives\",\"not_alone\",\"FsizeD\"]\n",
    "\n",
    "testdf_features = testdf_map.fit_transform(testdf)\n",
    "\n",
    "\n",
    "\n",
    "# Predict classes of test set and evaluate\n",
    "titanic_rf_pred = titanic_rf_clf.predict(titanic_features_test)\n",
    "\n",
    "titanic_rf_cm = metrics.confusion_matrix(titanic.loc[titanic.is_train==False, 'Survived'],\n",
    "                                         titanic_rf_pred, labels=[0,1])\n",
    "print(titanic_rf_cm)\n",
    "titanic_rf_acc = metrics.accuracy_score(titanic.loc[titanic.is_train==False, 'Survived'],\n",
    "                                         titanic_rf_pred)\n",
    "titanic_rf_prec = metrics.precision_score(titanic.loc[titanic.is_train==False, 'Survived'],\n",
    "                                          titanic_rf_pred)\n",
    "titanic_rf_rec = metrics.recall_score(titanic.loc[titanic.is_train==False, 'Survived'],\n",
    "                                      titanic_rf_pred)\n",
    "titanic_rf_f1 = metrics.f1_score(titanic.loc[titanic.is_train==False, 'Survived'],\n",
    "                                      titanic_rf_pred)\n",
    "\n",
    "# Predict probabilities to calculate AUC\n",
    "titanic_rf_pred_prob = titanic_rf_clf.predict_proba(titanic_features_test)\n",
    "\n",
    "titanic_rf_auc = metrics.roc_auc_score(titanic.loc[titanic.is_train==False, 'Survived'],\n",
    "                                       titanic_rf_pred_prob[:,1])\n",
    "\n",
    "print(\"Accuracy: \" + str(titanic_rf_acc) + \"\\nPrecision: \" \n",
    "      + str(titanic_rf_prec) + \"\\nRecall: \" + str(titanic_rf_rec)\n",
    "      + \"\\nF1-score: \" + str(titanic_rf_f1) + \"\\nAUC: \" + str(titanic_rf_auc))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_rf_test = titanic_rf_clf.predict(testdf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do we have 418 records?\n",
    "len(titanic_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(titanic_rf_test, columns=['Survived'])\n",
    "testread = pd.read_csv('Datasets/titanic_test.csv')\n",
    "predictions = pd.concat((testread.iloc[:, 0], predictions), axis = 1)\n",
    "predictions.to_csv('random_forest.csv', sep=\",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('Datasets/random_forest.csv', sep=\",\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
